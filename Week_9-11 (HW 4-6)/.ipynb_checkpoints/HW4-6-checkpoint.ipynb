{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Crawling and Text Analysis\n",
    "\n",
    "# Topic: Selecting Meaningful Words From Reuter News Articles (In Preparation for News Sentiment Analysis)\n",
    "\n",
    "#### The result of this analysis can applied to our final project, where we will anlayze how news sentiment can effect the performance of ETFs\n",
    "\n",
    "- We will start with news articles from Reuters, eventually expanding to multiple news sources\n",
    "- Due to time constraints, the scope of the assinment will be limited to US equities market. \n",
    "- S&P 500 will serve as our market index for the time \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as font_manager\n",
    "import numpy as np\n",
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas_datareader.data as web\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting price data for S&P500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-10-01</th>\n",
       "      <td>2937.060059</td>\n",
       "      <td>2917.909912</td>\n",
       "      <td>2926.290039</td>\n",
       "      <td>2924.590088</td>\n",
       "      <td>3364190000</td>\n",
       "      <td>2924.590088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-02</th>\n",
       "      <td>2931.419922</td>\n",
       "      <td>2919.370117</td>\n",
       "      <td>2923.800049</td>\n",
       "      <td>2923.429932</td>\n",
       "      <td>3401880000</td>\n",
       "      <td>2923.429932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-03</th>\n",
       "      <td>2939.860107</td>\n",
       "      <td>2921.360107</td>\n",
       "      <td>2931.689941</td>\n",
       "      <td>2925.510010</td>\n",
       "      <td>3598710000</td>\n",
       "      <td>2925.510010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-04</th>\n",
       "      <td>2919.780029</td>\n",
       "      <td>2883.919922</td>\n",
       "      <td>2919.350098</td>\n",
       "      <td>2901.610107</td>\n",
       "      <td>3496860000</td>\n",
       "      <td>2901.610107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-05</th>\n",
       "      <td>2909.639893</td>\n",
       "      <td>2869.290039</td>\n",
       "      <td>2902.540039</td>\n",
       "      <td>2885.570068</td>\n",
       "      <td>3328980000</td>\n",
       "      <td>2885.570068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   High          Low         Open        Close      Volume  \\\n",
       "Date                                                                         \n",
       "2018-10-01  2937.060059  2917.909912  2926.290039  2924.590088  3364190000   \n",
       "2018-10-02  2931.419922  2919.370117  2923.800049  2923.429932  3401880000   \n",
       "2018-10-03  2939.860107  2921.360107  2931.689941  2925.510010  3598710000   \n",
       "2018-10-04  2919.780029  2883.919922  2919.350098  2901.610107  3496860000   \n",
       "2018-10-05  2909.639893  2869.290039  2902.540039  2885.570068  3328980000   \n",
       "\n",
       "              Adj Close  \n",
       "Date                     \n",
       "2018-10-01  2924.590088  \n",
       "2018-10-02  2923.429932  \n",
       "2018-10-03  2925.510010  \n",
       "2018-10-04  2901.610107  \n",
       "2018-10-05  2885.570068  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grabs open, high, low, close price data for SP500\n",
    "def SP500(startDate, endDate):\n",
    "    sp = web.DataReader('^GSPC', 'yahoo', startDate, endDate)\n",
    "    sp = sp.resample('D').ffill()\n",
    "    return sp\n",
    "\n",
    "startDate = dt.date(2018,10,1)\n",
    "endDate = dt.date.today()\n",
    "SP = SP500(startDate, endDate)\n",
    "SP.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting news articles from Reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab links to news articles from reuter's archive page\n",
    "# ten+ articles are displayed on each page\n",
    "url_links = []\n",
    "for i in range(1,100):\n",
    "    url = 'https://www.reuters.com/news/archive/marketsNews?view=page&page=' + str(i) + '&pageSize=10'\n",
    "    html = requests.get(url)\n",
    "    content = html.content\n",
    "    content.decode().strip().replace('\\t','').split('\\n')\n",
    "    soup = BeautifulSoup(content, \"html.parser\")\n",
    "    for tags in soup.find_all('a'):\n",
    "        if re.search('article', tags['href']):\n",
    "            url_links.append(tags['href'])\n",
    "            \n",
    "# some linkes may be duplicated thus we only select those that only appear once\n",
    "final_urls = []\n",
    "for url in url_links:\n",
    "    if url not in final_urls:\n",
    "        final_urls.append(url)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# retreive the title, publish time and content for each article\n",
    "\n",
    "title_all = []\n",
    "time_all = []\n",
    "content_all = []\n",
    "url_all = []\n",
    "\n",
    "for url in final_urls:\n",
    "    link = 'https://www.reuters.com' + url\n",
    "    page = requests.get(link).content\n",
    "    soup = BeautifulSoup(page, \"html.parser\")\n",
    "    newsTitle = soup.title.text\n",
    "    print(newsTitle.lstrip())\n",
    "    print(link, '\\n')\n",
    "    newsTime = soup.find_all(\"div\", {\"class\": 'ArticleHeader_date'})[0].text\n",
    "    newsContent = ''\n",
    "    for tag in soup.find_all('p'):\n",
    "        newsContent += tag.text\n",
    "        \n",
    "    title_all.append(newsTitle)\n",
    "    time_all.append(newsTime)\n",
    "    content_all.append(newsContent)\n",
    "    url_all.append(link)\n",
    "\n",
    "# remove spaces infront of titles\n",
    "title_all = [x.lstrip() for x in title_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Time</th>\n",
       "      <th>Content</th>\n",
       "      <th>Link</th>\n",
       "      <th>Date</th>\n",
       "      <th>Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fed's Clarida says there's no good case for ra...</td>\n",
       "      <td>May 7, 2019 /  2:34 PM / in 3 minutes</td>\n",
       "      <td>2 Min ReadWASHINGTON (Reuters) - The U.S. Fede...</td>\n",
       "      <td>https://www.reuters.com/article/usa-fed-clarid...</td>\n",
       "      <td>2019-05-07</td>\n",
       "      <td>1311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Investors most neutral on U.S. Treasuries in f...</td>\n",
       "      <td>May 7, 2019 /  2:37 PM / a minute ago</td>\n",
       "      <td>1 Min ReadNEW YORK, May 7 (Reuters) - Bond inv...</td>\n",
       "      <td>https://www.reuters.com/article/treasuries-jpm...</td>\n",
       "      <td>2019-05-07</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fed's Clarida says there's no good case for ra...</td>\n",
       "      <td>May 7, 2019 /  2:28 PM / Updated 16 minutes ago</td>\n",
       "      <td>1 Min ReadWASHINGTON, May 7 (Reuters) - The U....</td>\n",
       "      <td>https://www.reuters.com/article/usa-fed-clarid...</td>\n",
       "      <td>2019-05-07</td>\n",
       "      <td>677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UPDATE 1-Sterling slides to day's low on Brexi...</td>\n",
       "      <td>May 7, 2019 /  2:27 PM / in a minute</td>\n",
       "      <td>3 Min Read* Graphic: World FX rates in 2019 tm...</td>\n",
       "      <td>https://www.reuters.com/article/britain-sterli...</td>\n",
       "      <td>2019-05-07</td>\n",
       "      <td>2876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CANADA STOCKS-TSX falls for second day on U.S....</td>\n",
       "      <td>May 7, 2019 /  2:28 PM / Updated 16 minutes ago</td>\n",
       "      <td>2 Min ReadMay 7 (Reuters) - Canada’s main stoc...</td>\n",
       "      <td>https://www.reuters.com/article/canada-stocks/...</td>\n",
       "      <td>2019-05-07</td>\n",
       "      <td>2056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wall Street declines on U.S.-China trade tensi...</td>\n",
       "      <td>May 7, 2019 /  11:08 AM / Updated 13 minutes ago</td>\n",
       "      <td>4 Min Read(Reuters) - U.S. stocks posted broad...</td>\n",
       "      <td>https://www.reuters.com/article/usa-stocks/us-...</td>\n",
       "      <td>2019-05-07</td>\n",
       "      <td>3312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Scout24 bidders reach 9.7 percent stake ahead ...</td>\n",
       "      <td>May 7, 2019 /  2:33 PM / in a minute</td>\n",
       "      <td>1 Min ReadBERLIN (Reuters) - The private equit...</td>\n",
       "      <td>https://www.reuters.com/article/scout24-ag-ma/...</td>\n",
       "      <td>2019-05-07</td>\n",
       "      <td>677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Britain will take part in European Parliament ...</td>\n",
       "      <td>May 7, 2019 /  2:33 PM / a few seconds ago</td>\n",
       "      <td>1 Min ReadLONDON (Reuters) - Britain will have...</td>\n",
       "      <td>https://www.reuters.com/article/britain-eu-ele...</td>\n",
       "      <td>2019-05-07</td>\n",
       "      <td>1173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Senate's McConnell to declare 'case closed' on...</td>\n",
       "      <td>May 7, 2019 /  1:25 PM / in an hour</td>\n",
       "      <td>4 Min ReadWASHINGTON (Reuters) - The divided U...</td>\n",
       "      <td>https://www.reuters.com/article/us-usa-trump-c...</td>\n",
       "      <td>2019-05-07</td>\n",
       "      <td>3435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>U.S. House panel readies contempt vote against...</td>\n",
       "      <td>May 6, 2019 /  5:02 AM / Updated 11 hours ago</td>\n",
       "      <td>4 Min ReadWASHINGTON (Reuters) - Congressional...</td>\n",
       "      <td>https://www.reuters.com/article/us-usa-trump-b...</td>\n",
       "      <td>2019-05-06</td>\n",
       "      <td>4048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  \\\n",
       "1   Fed's Clarida says there's no good case for ra...   \n",
       "2   Investors most neutral on U.S. Treasuries in f...   \n",
       "4   Fed's Clarida says there's no good case for ra...   \n",
       "5   UPDATE 1-Sterling slides to day's low on Brexi...   \n",
       "6   CANADA STOCKS-TSX falls for second day on U.S....   \n",
       "7   Wall Street declines on U.S.-China trade tensi...   \n",
       "8   Scout24 bidders reach 9.7 percent stake ahead ...   \n",
       "9   Britain will take part in European Parliament ...   \n",
       "10  Senate's McConnell to declare 'case closed' on...   \n",
       "11  U.S. House panel readies contempt vote against...   \n",
       "\n",
       "                                                Time  \\\n",
       "1              May 7, 2019 /  2:34 PM / in 3 minutes   \n",
       "2              May 7, 2019 /  2:37 PM / a minute ago   \n",
       "4    May 7, 2019 /  2:28 PM / Updated 16 minutes ago   \n",
       "5               May 7, 2019 /  2:27 PM / in a minute   \n",
       "6    May 7, 2019 /  2:28 PM / Updated 16 minutes ago   \n",
       "7   May 7, 2019 /  11:08 AM / Updated 13 minutes ago   \n",
       "8               May 7, 2019 /  2:33 PM / in a minute   \n",
       "9         May 7, 2019 /  2:33 PM / a few seconds ago   \n",
       "10               May 7, 2019 /  1:25 PM / in an hour   \n",
       "11     May 6, 2019 /  5:02 AM / Updated 11 hours ago   \n",
       "\n",
       "                                              Content  \\\n",
       "1   2 Min ReadWASHINGTON (Reuters) - The U.S. Fede...   \n",
       "2   1 Min ReadNEW YORK, May 7 (Reuters) - Bond inv...   \n",
       "4   1 Min ReadWASHINGTON, May 7 (Reuters) - The U....   \n",
       "5   3 Min Read* Graphic: World FX rates in 2019 tm...   \n",
       "6   2 Min ReadMay 7 (Reuters) - Canada’s main stoc...   \n",
       "7   4 Min Read(Reuters) - U.S. stocks posted broad...   \n",
       "8   1 Min ReadBERLIN (Reuters) - The private equit...   \n",
       "9   1 Min ReadLONDON (Reuters) - Britain will have...   \n",
       "10  4 Min ReadWASHINGTON (Reuters) - The divided U...   \n",
       "11  4 Min ReadWASHINGTON (Reuters) - Congressional...   \n",
       "\n",
       "                                                 Link       Date   Len  \n",
       "1   https://www.reuters.com/article/usa-fed-clarid... 2019-05-07  1311  \n",
       "2   https://www.reuters.com/article/treasuries-jpm... 2019-05-07   747  \n",
       "4   https://www.reuters.com/article/usa-fed-clarid... 2019-05-07   677  \n",
       "5   https://www.reuters.com/article/britain-sterli... 2019-05-07  2876  \n",
       "6   https://www.reuters.com/article/canada-stocks/... 2019-05-07  2056  \n",
       "7   https://www.reuters.com/article/usa-stocks/us-... 2019-05-07  3312  \n",
       "8   https://www.reuters.com/article/scout24-ag-ma/... 2019-05-07   677  \n",
       "9   https://www.reuters.com/article/britain-eu-ele... 2019-05-07  1173  \n",
       "10  https://www.reuters.com/article/us-usa-trump-c... 2019-05-07  3435  \n",
       "11  https://www.reuters.com/article/us-usa-trump-b... 2019-05-06  4048  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save all articles to one csv file\n",
    "file = pd.DataFrame({'Title' : title_all, 'Time':time_all, 'Content':content_all, 'Link':url_all})\n",
    "file['Date'] = [x.split('/')[0] for x in file['Time'].tolist()]\n",
    "file['Date'] = pd.to_datetime(file['Date'])\n",
    "\n",
    "file['Len'] = [len(x) for x in file['Content']]\n",
    "file = file[file['Len'] >= 600]\n",
    "\n",
    "file.to_csv('articles.csv')\n",
    "file.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pd.read_csv('articles.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>001</th>\n",
       "      <th>002</th>\n",
       "      <th>005</th>\n",
       "      <th>006</th>\n",
       "      <th>008</th>\n",
       "      <th>009</th>\n",
       "      <th>01</th>\n",
       "      <th>...</th>\n",
       "      <th>zone</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zooming</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>zug</th>\n",
       "      <th>zuma</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zwaan</th>\n",
       "      <th>ﬂat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 17321 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  0000  001  002  005  006  008  009  01  ...  zone  zones  zoom  \\\n",
       "0   0    0     0    0    0    0    0    0    0   0  ...     0      0     0   \n",
       "1   0    0     0    0    0    0    0    0    0   0  ...     0      0     0   \n",
       "2   0    0     0    0    0    0    0    0    0   0  ...     0      0     0   \n",
       "3   0    0     0    0    0    0    0    0    0   0  ...     0      0     0   \n",
       "4   0    0     0    0    0    0    0    0    0   0  ...     0      0     0   \n",
       "\n",
       "   zooming  zuckerberg  zug  zuma  zurich  zwaan  ﬂat  \n",
       "0        0           0    0     0       0      0    0  \n",
       "1        0           0    0     0       0      0    0  \n",
       "2        0           0    0     0       0      0    0  \n",
       "3        0           0    0     0       0      0    0  \n",
       "4        0           0    0     0       0      0    0  \n",
       "\n",
       "[5 rows x 17321 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Getting the word frequency matrix with sklearn\n",
    "corpus = file['Content'].values.tolist()\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()  \n",
    "X = vectorizer.fit_transform(corpus)  \n",
    "word = vectorizer.get_feature_names()  \n",
    "pd.DataFrame(X.toarray(), columns=word).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>001</th>\n",
       "      <th>002</th>\n",
       "      <th>005</th>\n",
       "      <th>006</th>\n",
       "      <th>008</th>\n",
       "      <th>009</th>\n",
       "      <th>01</th>\n",
       "      <th>...</th>\n",
       "      <th>zone</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zooming</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>zug</th>\n",
       "      <th>zuma</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zwaan</th>\n",
       "      <th>ﬂat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 17321 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00  000  0000  001  002  005  006  008  009   01  ...  zone  zones  zoom  \\\n",
       "0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0    0.0   0.0   \n",
       "1  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0    0.0   0.0   \n",
       "2  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0    0.0   0.0   \n",
       "3  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0    0.0   0.0   \n",
       "4  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0    0.0   0.0   \n",
       "\n",
       "   zooming  zuckerberg  zug  zuma  zurich  zwaan  ﬂat  \n",
       "0      0.0         0.0  0.0   0.0     0.0    0.0  0.0  \n",
       "1      0.0         0.0  0.0   0.0     0.0    0.0  0.0  \n",
       "2      0.0         0.0  0.0   0.0     0.0    0.0  0.0  \n",
       "3      0.0         0.0  0.0   0.0     0.0    0.0  0.0  \n",
       "4      0.0         0.0  0.0   0.0     0.0    0.0  0.0  \n",
       "\n",
       "[5 rows x 17321 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "transformer = TfidfTransformer(smooth_idf = False)\n",
    "tfidf = transformer.fit_transform(X)\n",
    "\n",
    "df_tfidf = pd.DataFrame(tfidf.toarray(), columns=word)\n",
    "df_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15672</th>\n",
       "      <td>the</td>\n",
       "      <td>207.783551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15834</th>\n",
       "      <td>to</td>\n",
       "      <td>107.751337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10990</th>\n",
       "      <td>of</td>\n",
       "      <td>107.130755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1810</th>\n",
       "      <td>and</td>\n",
       "      <td>90.901376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8206</th>\n",
       "      <td>in</td>\n",
       "      <td>89.735710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11058</th>\n",
       "      <td>on</td>\n",
       "      <td>57.047368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6807</th>\n",
       "      <td>for</td>\n",
       "      <td>48.633942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3206</th>\n",
       "      <td>by</td>\n",
       "      <td>48.426135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13751</th>\n",
       "      <td>said</td>\n",
       "      <td>40.649421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11602</th>\n",
       "      <td>percent</td>\n",
       "      <td>39.505660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index           0\n",
       "15672      the  207.783551\n",
       "15834       to  107.751337\n",
       "10990       of  107.130755\n",
       "1810       and   90.901376\n",
       "8206        in   89.735710\n",
       "11058       on   57.047368\n",
       "6807       for   48.633942\n",
       "3206        by   48.426135\n",
       "13751     said   40.649421\n",
       "11602  percent   39.505660"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidf.sum().reset_index().sort_values([0], ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14209</th>\n",
       "      <td>sheffield</td>\n",
       "      <td>0.014541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14330</th>\n",
       "      <td>sibley</td>\n",
       "      <td>0.014541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11322</th>\n",
       "      <td>overy</td>\n",
       "      <td>0.014541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0920</td>\n",
       "      <td>0.014541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762</th>\n",
       "      <td>amelia</td>\n",
       "      <td>0.014541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0930</td>\n",
       "      <td>0.014541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11394</th>\n",
       "      <td>panetta</td>\n",
       "      <td>0.014541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7616</th>\n",
       "      <td>haskel</td>\n",
       "      <td>0.014541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>1630</td>\n",
       "      <td>0.014541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2974</th>\n",
       "      <td>brazier</td>\n",
       "      <td>0.014541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           index         0\n",
       "14209  sheffield  0.014541\n",
       "14330     sibley  0.014541\n",
       "11322      overy  0.014541\n",
       "92          0920  0.014541\n",
       "1762      amelia  0.014541\n",
       "93          0930  0.014541\n",
       "11394    panetta  0.014541\n",
       "7616      haskel  0.014541\n",
       "259         1630  0.014541\n",
       "2974     brazier  0.014541"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidf.sum().reset_index().sort_values([0], ascending = False).tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally we would expect words such as \"the\" and \"to\" to get zero weighting from the inverse document frequency, as it is appeared in almost all articles. However, with the imported function \"TfidfTransformer,\" idf is computed as idf(t) = log [ n / df(t)] + 1. This means that words that occur in all documents will still receive a weighting greater than zero. This feature conflicts with our aim to remove words that have no meaning. In the following we will calcualate our own TF-IDF. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>\"avengers:</th>\n",
       "      <th>\"case</th>\n",
       "      <th>\"disastrous\"</th>\n",
       "      <th>\"has</th>\n",
       "      <th>\"hush</th>\n",
       "      <th>\"letting</th>\n",
       "      <th>\"one</th>\n",
       "      <th>\"other</th>\n",
       "      <th>\"raise</th>\n",
       "      <th>...</th>\n",
       "      <th>“you’d</th>\n",
       "      <th>“you’re</th>\n",
       "      <th>“you’ve</th>\n",
       "      <th>“yuan</th>\n",
       "      <th>“zainab</th>\n",
       "      <th>“‘black</th>\n",
       "      <th>“‘sell</th>\n",
       "      <th>“”restoring</th>\n",
       "      <th>…</th>\n",
       "      <th>ﬂat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31695 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        \"avengers:  \"case  \"disastrous\"  \"has  \"hush  \"letting  \"one  \"other  \\\n",
       "0  0.0         0.0    0.0           0.0   0.0    0.0       0.0   0.0     0.0   \n",
       "0  0.0         0.0    0.0           0.0   0.0    0.0       0.0   0.0     0.0   \n",
       "0  0.0         0.0    0.0           0.0   0.0    0.0       0.0   0.0     0.0   \n",
       "0  0.0         0.0    0.0           0.0   0.0    0.0       0.0   0.0     0.0   \n",
       "0  0.0         0.0    0.0           0.0   0.0    0.0       0.0   0.0     0.0   \n",
       "\n",
       "   \"raise  ...  “you’d  “you’re  “you’ve  “yuan  “zainab  “‘black  “‘sell  \\\n",
       "0     0.0  ...     0.0      0.0      0.0    0.0      0.0      0.0     0.0   \n",
       "0     0.0  ...     0.0      0.0      0.0    0.0      0.0      0.0     0.0   \n",
       "0     0.0  ...     0.0      0.0      0.0    0.0      0.0      0.0     0.0   \n",
       "0     0.0  ...     0.0      0.0      0.0    0.0      0.0      0.0     0.0   \n",
       "0     0.0  ...     0.0      0.0      0.0    0.0      0.0      0.0     0.0   \n",
       "\n",
       "   “”restoring    …  ﬂat  \n",
       "0          0.0  0.0  0.0  \n",
       "0          0.0  0.0  0.0  \n",
       "0          0.0  0.0  0.0  \n",
       "0          0.0  0.0  0.0  \n",
       "0          0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 31695 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine the content of all articles to one list\n",
    "text_all = []\n",
    "for content in file['Content']:\n",
    "    text = content.split(' ')\n",
    "    text = [x.lower() for x in text]\n",
    "    text_all.append(text)\n",
    "\n",
    "\n",
    "# calculate term frequency in each article\n",
    "def computeReviewTFDict(reviews):\n",
    "    # counts the number of times the word appears in review\n",
    "    all_TFDict = []\n",
    "    for review in reviews:\n",
    "        reviewTFDict = {}\n",
    "        for word in review:\n",
    "            if word in reviewTFDict:\n",
    "                reviewTFDict[word] += 1\n",
    "            else:\n",
    "                reviewTFDict[word] = 1\n",
    "        all_TFDict.append(reviewTFDict)\n",
    "    \n",
    "    return all_TFDict\n",
    "\n",
    "TF = computeReviewTFDict(text_all)\n",
    "TF_list = [pd.DataFrame(list(doc.values()), index=doc.keys()) for doc in TF]\n",
    "wfm = pd.concat(TF_list, axis= 1)\n",
    "wfm = np.transpose(wfm).fillna(0)\n",
    "wfm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>complete</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>for</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>exchanges</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>quotes</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>list</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>minutes.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>of</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index    0\n",
       "0         15  0.0\n",
       "1   complete  0.0\n",
       "2        for  0.0\n",
       "3       2019  0.0\n",
       "4  exchanges  0.0\n",
       "5     quotes  0.0\n",
       "6          a  0.0\n",
       "7       list  0.0\n",
       "8   minutes.  0.0\n",
       "9         of  0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inverse Document Frequency requires the number of documents each word has appeared in \n",
    "\n",
    "import math\n",
    "total_words = wfm.astype(bool).sum(axis=0).sum()\n",
    "\n",
    "#Total number of documents / Number of documents with term in it\n",
    "idf = len(wfm)/wfm.astype(bool).sum(axis=0)\n",
    "\n",
    "# Taking log\n",
    "idf = idf.apply(math.log)\n",
    "\n",
    "idf = idf.sort_values().reset_index()\n",
    "idf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31685</th>\n",
       "      <td>opec+</td>\n",
       "      <td>6.908755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31686</th>\n",
       "      <td>opec+,</td>\n",
       "      <td>6.908755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31687</th>\n",
       "      <td>opec+.</td>\n",
       "      <td>6.908755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31688</th>\n",
       "      <td>opec,</td>\n",
       "      <td>6.908755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31689</th>\n",
       "      <td>collapsed,</td>\n",
       "      <td>6.908755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31690</th>\n",
       "      <td>collaborations.”</td>\n",
       "      <td>6.908755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31691</th>\n",
       "      <td>collaboration</td>\n",
       "      <td>6.908755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31692</th>\n",
       "      <td>collaborating</td>\n",
       "      <td>6.908755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31693</th>\n",
       "      <td>ontario-based</td>\n",
       "      <td>6.908755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31694</th>\n",
       "      <td>benkoe)all</td>\n",
       "      <td>6.908755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  index         0\n",
       "31685             opec+  6.908755\n",
       "31686            opec+,  6.908755\n",
       "31687            opec+.  6.908755\n",
       "31688             opec,  6.908755\n",
       "31689        collapsed,  6.908755\n",
       "31690  collaborations.”  6.908755\n",
       "31691     collaboration  6.908755\n",
       "31692     collaborating  6.908755\n",
       "31693     ontario-based  6.908755\n",
       "31694        benkoe)all  6.908755"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem with words appearing in all articles seems to be solved as words such a \"the\" and \"a\" now have zero weighting. However, we need to address the issue with punctuation and symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>minutes</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>complete</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>exchanges</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>quotes</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>reuters</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>list</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>of</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>delayed</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>and</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>delays</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rights</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>for</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>reserved</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>a</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>minimum</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>here</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>see</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>15</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>all</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>o’brien</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>coowner</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>o’key</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>o’neill</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ozel</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>conveying</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>conveyances</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>converting</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>paced</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          index         0\n",
       "0       minutes  0.000000\n",
       "1      complete  0.000000\n",
       "2          2019  0.000000\n",
       "3     exchanges  0.000000\n",
       "4        quotes  0.000000\n",
       "5       reuters  0.000000\n",
       "6          list  0.000000\n",
       "7           min  0.000000\n",
       "8            of  0.000000\n",
       "9       delayed  0.000000\n",
       "10          and  0.000000\n",
       "11       delays  0.000000\n",
       "12       rights  0.000000\n",
       "13          for  0.000000\n",
       "14     reserved  0.000000\n",
       "15            a  0.000000\n",
       "16      minimum  0.000000\n",
       "17         here  0.000000\n",
       "18          see  0.000000\n",
       "19           15  0.000000\n",
       "20          all  0.000000\n",
       "21      o’brien  0.000028\n",
       "22      coowner  0.000028\n",
       "23        o’key  0.000028\n",
       "24      o’neill  0.000028\n",
       "25         ozel  0.000028\n",
       "26    conveying  0.000028\n",
       "27  conveyances  0.000028\n",
       "28   converting  0.000028\n",
       "29        paced  0.000028"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import math\n",
    "\n",
    "exclude = set(string.punctuation + '©…”“‘—')\n",
    "\n",
    "# combine the content of all articles to one list while removing punctuations\n",
    "text_all = []\n",
    "for content in file['Content']:\n",
    "    text = ''.join(ch for ch in content if ch not in exclude)\n",
    "    text = text.split(' ')\n",
    "    text = [x.lower() for x in text]\n",
    "    text_all.append(text)\n",
    "\n",
    "\n",
    "# calculate term frequency in each article\n",
    "def computeReviewTFDict(reviews):\n",
    "    # counts the number of times the word appears in review\n",
    "    all_TFDict = []\n",
    "    for review in reviews:\n",
    "        reviewTFDict = {}\n",
    "        for word in review:\n",
    "            if word in reviewTFDict:\n",
    "                reviewTFDict[word] += 1\n",
    "            else:\n",
    "                reviewTFDict[word] = 1\n",
    "        all_TFDict.append(reviewTFDict)\n",
    "    \n",
    "    return all_TFDict\n",
    "\n",
    "TF = computeReviewTFDict(text_all)\n",
    "TF_list = [pd.DataFrame(list(doc.values()), index=doc.keys()) for doc in TF]\n",
    "wfm = pd.concat(TF_list, axis= 1)\n",
    "wfm = np.transpose(wfm).fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "total_words = wfm.astype(bool).sum(axis=0).sum()\n",
    "tf = wfm.sum()/total_words\n",
    "\n",
    "\n",
    "#Total number of documents / Number of documents with term in it\n",
    "idf = len(wfm)/wfm.astype(bool).sum(axis=0)\n",
    "# Taking log\n",
    "idf = idf.apply(math.log)\n",
    "\n",
    "tfidf = tf*idf\n",
    "tfidf = tfidf.sort_values().reset_index()\n",
    "tfidf.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20731</th>\n",
       "      <td>governor</td>\n",
       "      <td>0.003335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20732</th>\n",
       "      <td>president</td>\n",
       "      <td>0.003346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20733</th>\n",
       "      <td>data</td>\n",
       "      <td>0.003405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20734</th>\n",
       "      <td>campaign</td>\n",
       "      <td>0.003426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20735</th>\n",
       "      <td>its</td>\n",
       "      <td>0.003505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20736</th>\n",
       "      <td>china</td>\n",
       "      <td>0.003540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20737</th>\n",
       "      <td>mueller</td>\n",
       "      <td>0.003542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20738</th>\n",
       "      <td>sp</td>\n",
       "      <td>0.003596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20739</th>\n",
       "      <td>holds</td>\n",
       "      <td>0.003695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20740</th>\n",
       "      <td>fed</td>\n",
       "      <td>0.003695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20741</th>\n",
       "      <td>billion</td>\n",
       "      <td>0.003705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20742</th>\n",
       "      <td>dollar</td>\n",
       "      <td>0.003723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20743</th>\n",
       "      <td>report</td>\n",
       "      <td>0.003748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20744</th>\n",
       "      <td>inflation</td>\n",
       "      <td>0.003833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20745</th>\n",
       "      <td>house</td>\n",
       "      <td>0.003874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20746</th>\n",
       "      <td>central</td>\n",
       "      <td>0.003917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20747</th>\n",
       "      <td>federal</td>\n",
       "      <td>0.003952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20748</th>\n",
       "      <td>new</td>\n",
       "      <td>0.003959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20749</th>\n",
       "      <td>trade</td>\n",
       "      <td>0.004049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20750</th>\n",
       "      <td>reserve</td>\n",
       "      <td>0.004350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20751</th>\n",
       "      <td>rate</td>\n",
       "      <td>0.004443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20752</th>\n",
       "      <td>meeting</td>\n",
       "      <td>0.004815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20753</th>\n",
       "      <td>he</td>\n",
       "      <td>0.005014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20754</th>\n",
       "      <td>policy</td>\n",
       "      <td>0.005064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20755</th>\n",
       "      <td>his</td>\n",
       "      <td>0.005106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20756</th>\n",
       "      <td>monetary</td>\n",
       "      <td>0.005264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20757</th>\n",
       "      <td>trump</td>\n",
       "      <td>0.006363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20758</th>\n",
       "      <td>gmt</td>\n",
       "      <td>0.006600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20759</th>\n",
       "      <td>percent</td>\n",
       "      <td>0.007223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20760</th>\n",
       "      <td>bank</td>\n",
       "      <td>0.007543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           index         0\n",
       "20731   governor  0.003335\n",
       "20732  president  0.003346\n",
       "20733       data  0.003405\n",
       "20734   campaign  0.003426\n",
       "20735        its  0.003505\n",
       "20736      china  0.003540\n",
       "20737    mueller  0.003542\n",
       "20738         sp  0.003596\n",
       "20739      holds  0.003695\n",
       "20740        fed  0.003695\n",
       "20741    billion  0.003705\n",
       "20742     dollar  0.003723\n",
       "20743     report  0.003748\n",
       "20744  inflation  0.003833\n",
       "20745      house  0.003874\n",
       "20746    central  0.003917\n",
       "20747    federal  0.003952\n",
       "20748        new  0.003959\n",
       "20749      trade  0.004049\n",
       "20750    reserve  0.004350\n",
       "20751       rate  0.004443\n",
       "20752    meeting  0.004815\n",
       "20753         he  0.005014\n",
       "20754     policy  0.005064\n",
       "20755        his  0.005106\n",
       "20756   monetary  0.005264\n",
       "20757      trump  0.006363\n",
       "20758        gmt  0.006600\n",
       "20759    percent  0.007223\n",
       "20760       bank  0.007543"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.tail(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Follow ups\n",
    "\n",
    "1. Using TF-IDF we identify words such as \"a\" and \"for\" to carry very little meaningful information about the actual content, as they appear in all articles. These words will be excluded from future analysis. \n",
    "\n",
    "\n",
    "2. Words such as \"policy\" and \"reserve\" are the terms we are most interested in. We will be focusing on these words in our sentiment analysis. \n",
    "\n",
    "\n",
    "3. Before we continue with this set of words, we will need to solve the problem with stemming. For example, the word \"reserve\" and \"reserves\" carry essentailly the same meaning though they are seperated as individual terms. Thus our text needs to be further modified before constructing our new TF-IDF. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
